# ==============================================================================
# Model Configuration for Multi-Agent Pipeline
# ==============================================================================
#
# This file maps each stage of the pipeline to a specific model.
# The model names should correspond to the keys in the AI provider settings.
#
# Supported models:
# - gemini_pro
# - grok_4
# - openai_o3
# - gemini_web_tool
# - grok_web_search
#

stages:
  INTENT:
    model: gemini_pro
    description: "Deduces metadata from the user prompt for downstream planning."

  PLAN:
    model: gemini_pro
    description: "Drafts a section outline and search agenda."

  SEARCH_A:
    model: gemini_web_tool
    description: "Web search using Gemini's tool."

  SEARCH_B:
    model: grok_web_search
    description: "Web search using Grok's search capabilities."

  SEARCH_C:
    model: openai_o3
    description: "Web search using OpenAI's o3 model with a browser tool."

  EVIDENCE:
    model: gemini_pro
    description: "Screens and filters search results to identify credible sources."

  WRITER:
    model: auto
    description: "Generates the main academic content. Model is chosen based on word count."
    rules:
      - model: gemini_pro
        max_tokens: 2500
      - model: grok_4
        min_tokens: 2501

  REWRITE:
    model: openai_o3
    description: "Paraphrases flagged content to improve quality and originality."
    config:
      temperature: 0.2

  QA_1:
    model: gemini_pro
    description: "Quality assessment with a specific rubric weight."
    config:
      weight: 0.6

  QA_2:
    model: gemini_pro
    description: "Quality assessment with a specific rubric weight."
    config:
      weight: 0.3

  QA_3:
    model: gemini_pro
    description: "Quality assessment with a specific rubric weight."
    config:
      weight: 0.1